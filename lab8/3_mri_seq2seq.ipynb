{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morphological Reinflection with Encoder-Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Morphological reinflection is the task of generating a target form given a source form, a source tag and a target tag.\n",
    "\n",
    "In this lab, we address on these tasks, i.e., Morphological reinflection, which is defined as:\n",
    "```\n",
    "Given an inflected form and its current tag, generate a target inflected form.\n",
    "\n",
    "English example:\n",
    "\n",
    "Source tag: Past \n",
    "Source form: ran \n",
    "Target tag: Present participle\n",
    "\n",
    "Output: running\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphological Reinflection with Seq2Seq\n",
    "\n",
    "In this lab, we will cover one of the fundamental breakthough method in solving this task with the use of Attention\n",
    "based Seq2Seq network, used by [Kann et al.](http://anthology.aclweb.org/P16-2090) in 2016 to win the competition.\n",
    "\n",
    "In subsequent years, multiple variants have been developed built on top of the vanilla Seq2seq model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os.path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset can be downloaded from [here](http://TODO). For this lab, we'll work with the German dataset, where each row contains the source and target:\n",
    "```\n",
    "pos=ADJ,case=ACC,comp=CMPR,gen=FEM,num=SG\taerodynamischere\tpos=ADJ,case=ACC,comp=SPRL,gen=NEUT,num=SG\taerodynamischstes\n",
    "pos=ADJ,case=ACC,comp=CMPR,gen=FEM,num=SG\taktivere\tpos=ADJ,case=NOM,comp=SPRL,gen=NEUT,num=SG\taktivstes\n",
    "pos=ADJ,case=ACC,comp=CMPR,gen=FEM,num=SG\tambitioniertere\tpos=ADJ,case=GEN,gen=FEM,num=SG\tambitionierter\n",
    "pos=ADJ,case=ACC,comp=CMPR,gen=FEM,num=SG\taufnahmefähigere\tpos=ADJ,case=DAT,comp=CMPR,gen=FEM,num=SG\taufnahmefähigerer\n",
    "```\n",
    "\n",
    "Information in first 3 columns are fed to the encoder and the decoder outputs the word in the last columns. We tokenize the word to character level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD_TOKEN = 0\n",
    "START_TOKEN = 1\n",
    "END_TOKEN = 2\n",
    "UNK_TOKEN = 3\n",
    "PAD_TAG = \"<pad>\"\n",
    "START_TAG = \"<w>\"\n",
    "END_TAG = \"</w>\"\n",
    "UNKNOWN_TAG = \"<unk>\"\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "def load_dataset(file_name):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    with open(file_name) as f:\n",
    "        for line in f.readlines():\n",
    "            example = line.split()\n",
    "            example[1] = example[1].lower()\n",
    "            example[3] = example[3].lower()\n",
    "            example[0] = example[0].split(\",\")\n",
    "            example[2] = example[2].split(\",\")\n",
    "            \n",
    "            if len(example[3]) <= MAX_LENGTH:\n",
    "                inputs.append(example[:3])\n",
    "                outputs.append(example[3])\n",
    "    return np.array(inputs), np.array(list(outputs))\n",
    "\n",
    "# Augment dataset by reversing the order, source->target becomes target->source\n",
    "def enhance_dataset(inputs, outputs):\n",
    "    # TODO implement\n",
    "    return inputs, outputs\n",
    "\n",
    "# We create 2 different vocab sets for source and target\n",
    "# because the source contains the set of morphological tags\n",
    "# which we do not require on the target end\n",
    "def preprocess_data(inputs, outputs, train=True):\n",
    "    if train:\n",
    "        inputs, outputs = enhance_dataset(inputs, outputs)\n",
    "    inputs = edit_tags(inputs)\n",
    "    inputs[:, [1, 2]] = inputs[:, [2, 1]]\n",
    "    inputs = transform_to_sequences(inputs)\n",
    "\n",
    "    input_vocab = get_vocab(inputs)\n",
    "    output_vocab = get_vocab(outputs)\n",
    "\n",
    "    return inputs, outputs, input_vocab, output_vocab\n",
    "\n",
    "# Specify input/output information in tags (from paper http://anthology.aclweb.org/P16-2090)\n",
    "def edit_tags(inputs):\n",
    "    for i in range(0, inputs.shape[0]):\n",
    "        inputs[i, 0] = np.array([\"IN=\" + x for x in inputs[i, 0]])\n",
    "        inputs[i, 2] = np.array([\"OUT=\" + x for x in inputs[i, 2]])\n",
    "    return inputs\n",
    "\n",
    "# tokenize words to characters\n",
    "def transform_to_sequences(inputs):\n",
    "    input_seq = np.array([np.concatenate((inputs[i, 0], inputs[i, 1], list(inputs[i, 2])))\n",
    "         for i in range(inputs.shape[0])])\n",
    "    return input_seq\n",
    "\n",
    "# create vocab map from data\n",
    "def get_vocab(data):\n",
    "    idx_to_char = {0: PAD_TAG, 1: START_TAG, 2: END_TAG, 3: UNKNOWN_TAG}\n",
    "    char_to_idx = {PAD_TAG: 0, START_TAG: 1, END_TAG: 2, UNKNOWN_TAG: 3}\n",
    "    char_set = set([])\n",
    "    for i in range(0, data.shape[0]):\n",
    "        char_set.update(data[i])\n",
    "    char_set = sorted(char_set)\n",
    "    for i in range(0, len(char_set)):\n",
    "        idx_to_char[i+4] = char_set[i]\n",
    "        char_to_idx[char_set[i]] = i+4\n",
    "    return idx_to_char, char_to_idx\n",
    "\n",
    "# return token indices\n",
    "def get_indices(input, vocab):\n",
    "    return  [vocab[ch] for ch in input] + [vocab[END_TAG]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset class\n",
    "We'll go ahead and define a Dataset class that reads data file and performs all the preprocessing ops defined above. \n",
    "\n",
    "We also define a collate function for padding while serving batches. Here we don't define a max_length for the input sequence as it only consists of a single word and a finite sequence of tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MEDDataset(Dataset):\n",
    "\n",
    "    def __init__(self, file_name, train=True):\n",
    "        inputs, outputs = load_dataset(file_name)\n",
    "        inputs, outputs, in_vocab, out_vocab = preprocess_data(inputs, outputs, train)\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        self.in_vocab = in_vocab\n",
    "        self.out_vocab = out_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.inputs.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        src = get_indices(self.inputs[index], self.in_vocab[1])\n",
    "        trg = get_indices(self.outputs[index], self.out_vocab[1])\n",
    "        return src, trg\n",
    "\n",
    "def med_collate_fn(data):\n",
    "\n",
    "    def _pad_sequences(seqs):\n",
    "        lens = [len(seq) for seq in seqs]\n",
    "        padded_seqs = torch.zeros(len(seqs), max(lens)).long()\n",
    "        for i, seq in enumerate(seqs):\n",
    "            end = lens[i]\n",
    "            padded_seqs[i, :end] = torch.LongTensor(seq[:end])\n",
    "        return padded_seqs, lens\n",
    "\n",
    "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    src_seqs, trg_seqs = zip(*data)\n",
    "    src_seqs, src_lens = _pad_sequences(src_seqs)\n",
    "    trg_seqs, trg_lens = _pad_sequences(trg_seqs)\n",
    "\n",
    "    #(batch, seq_len) => (seq_len, batch)\n",
    "    src_seqs = src_seqs.transpose(0,1)\n",
    "    trg_seqs = trg_seqs.transpose(0,1)\n",
    "\n",
    "    return src_seqs, src_lens, trg_seqs, trg_lens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Verifying the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure our ops are correct, we'll initialise the dataset and do a sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of source-target pairs: 1513\n",
      "Input:  ['IN=pos=ADJ', 'IN=case=ACC', 'IN=comp=CMPR', 'IN=gen=FEM', 'IN=num=SG', 'OUT=pos=ADJ', 'OUT=case=NOM', 'OUT=comp=SPRL', 'OUT=gen=NEUT', 'OUT=num=SG', 'a', 'k', 't', 'i', 'v', 'e', 'r', 'e', '</w>']\n",
      "\n",
      "\n",
      "Output:  ['a', 'k', 't', 'i', 'v', 's', 't', 'e', 's', '</w>']\n"
     ]
    }
   ],
   "source": [
    "# Initialize dataset\n",
    "dataset = MEDDataset(\"data/german-task2-train.txt\")\n",
    "\n",
    "print(\"Number of source-target pairs:\", len(dataset))\n",
    "print(\"Input: \", [dataset.in_vocab[0][_] for _ in dataset[0][0]])\n",
    "print(\"\\n\")\n",
    "print(\"Output: \", [dataset.out_vocab[0][_] for _ in dataset[0][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder is bidirectional and we use dropout in the GRU cell. The output states of the 2 directions are summed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, embed_size, hidden_size, n_layers=1, dropout=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, embed_size, padding_idx=PAD_TOKEN)\n",
    "        self.gru = nn.GRU(embed_size, hidden_size, n_layers, dropout=self.dropout, bidirectional=True)\n",
    "        \n",
    "    def forward(self, input_seqs, input_lengths, hidden=None):\n",
    "        # Note: we run this all at once (over multiple batches of multiple sequences)\n",
    "        embedded = self.embedding(input_seqs)\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs) # unpack (back to padded)\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:] # Sum bidirectional outputs\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Effective Approaches to Attention-based Neural Machine Translation by Luong et al.](https://arxiv.org/pdf/1508.04025.pdf) describe a few more attention models that offer improvements and simplifications. They describe a few \"global attention\" models, the distinction between them being the way the attention scores are calculated.\n",
    "\n",
    "The general form of the attention calculation relies on the target (decoder) side hidden state and corresponding source (encoder) side state, normalized over all states to get values summing to 1.\n",
    "\n",
    "The specific \"score\" function that compares two states is either dot, a simple dot product between the states; general, a a dot product between the decoder hidden state and a linear transform of the encoder state; or concat, a dot product between a new parameter $v_a$ and a linear transform of the states concatenated together.\n",
    "\n",
    "The modular definition of these scoring functions gives us an opportunity to build specific attention module that can switch between the different score methods. The input to this module is always the hidden state (of the decoder RNN) and set of encoder outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Attention Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        \n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "\n",
    "        # Create variable to store attention energies\n",
    "\n",
    "        # For each batch of encoder outputs\n",
    "        # Calculate energy for each encoder output\n",
    "        \n",
    "        # Normalize energies to weights in range 0 to 1, resize to 1 x B x S\n",
    "        \n",
    "        # Return context vectors\n",
    "        return None\n",
    "    \n",
    "    def score(self, hidden, encoder_output):\n",
    "        \n",
    "        if self.method == 'dot':\n",
    "            ## TODO implement\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'general':\n",
    "            energy = None\n",
    "            ## TODO implement \n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'concat':\n",
    "            energy = None\n",
    "            ## TODO implement \n",
    "            return energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Luong et al. Decoder model\n",
    "\n",
    "Now we can build a decoder that plugs this Attn module in after the RNN to calculate attention weights, and apply those weights to the encoder outputs to get a context vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # Keep for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size, padding_idx=PAD_TOKEN)\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout)\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        # Choose attention model\n",
    "        if attn_model != 'none':\n",
    "            self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, input_seq, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step at a time\n",
    "\n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        batch_size = input_seq.size(0)\n",
    "        embedded = self.embedding(input_seq)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        embedded = embedded.view(1, batch_size, self.hidden_size) # S=1 x B x N\n",
    "\n",
    "        # Get current hidden state from input word and last hidden state\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "\n",
    "        # Calculate attention from current RNN state and all encoder outputs;\n",
    "        # apply to encoder outputs to get weighted average\n",
    "        context = self.attn(rnn_output, encoder_outputs)\n",
    "\n",
    "        # Attentional vector using the RNN hidden state and context vector\n",
    "        # concatenated together (Luong eq. 5)\n",
    "        rnn_output = rnn_output.squeeze(0) # S=1 x B x N -> B x N\n",
    "        context = context.squeeze(1)       # B x S=1 x N -> B x N\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = F.tanh(self.concat(concat_input))\n",
    "\n",
    "        # Finally predict next token (Luong eq. 6, without softmax)\n",
    "        output = self.out(concat_output)\n",
    "\n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_step(src_batch, src_lens, trg_batch, trg_lens, encoder, decoder, \n",
    "               encoder_optimizer, decoder_optimizer, criterion):\n",
    "    \n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss, em_accuracy, edit_distance = 0.0, 0.0, 0.0\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(src_batch, src_lens, None)\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = torch.LongTensor([START_TOKEN] * batch_size).to(device)\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n",
    "\n",
    "    max_trg_len = max(trg_lens)\n",
    "\n",
    "    # Run through decoder one time step at a time using TEACHER FORCING=1.0\n",
    "    for t in range(max_trg_len):\n",
    "        decoder_output, decoder_hidden, decoder_attn = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs\n",
    "        )\n",
    "        loss += criterion(decoder_output, trg_batch[t])\n",
    "\n",
    "    # TODO implement accuracy\n",
    "    # TODO implement Levenshtein/edit distance\n",
    "        \n",
    "    loss = loss / max_trg_len\n",
    "    loss.backward()\n",
    "    \n",
    "    # Clip gradient norms\n",
    "    enc_grads = torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "    dec_grads = torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "\n",
    "    # Update parameters with optimizers\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item(), em_accuracy, edit_distance #, enc_grads, dec_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(encoder, decoder, checkpoint_dir):\n",
    "    enc_filename = \"{}/enc-{}.pth\".format(checkpoint_dir, time.strftime(\"%d%m%y-%H%M%S\"))\n",
    "    dec_filename = \"{}/dec-{}.pth\".format(checkpoint_dir, time.strftime(\"%d%m%y-%H%M%S\"))\n",
    "    torch.save(encoder.state_dict(), enc_filename)\n",
    "    torch.save(decoder.state_dict(), dec_filename)\n",
    "    print(\"Model saved.\")\n",
    "\n",
    "def train(dataset, batch_size, n_epochs, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, \n",
    "          checkpoint_dir=None, save_every=500):\n",
    "    train_iter = DataLoader(dataset=dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            num_workers=4,\n",
    "                            collate_fn=med_collate_fn,\n",
    "                            drop_last=True)\n",
    "    for i in range(n_epochs):\n",
    "        tick = time.clock()\n",
    "        print(\"Epoch {}/{}\".format(i+1, n_epochs))\n",
    "        losses, accs, eds = [], [], []\n",
    "        for batch_idx, batch in enumerate(train_iter):\n",
    "            input_batch, input_lengths, target_batch, target_lengths = batch\n",
    "            loss, accuracy, edit_distance = train_step(input_batch, input_lengths, target_batch, target_lengths, \n",
    "                                 encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "            losses.append(loss)\n",
    "            accs.append(accuracy)\n",
    "            eds.append(edit_distance)            \n",
    "            \n",
    "            if batch_idx % 100 == 0:\n",
    "                print(\"batch: {}, loss: {}, accuracy: {}, edit distance: {}\".format(batch_idx, loss, accuracy, \n",
    "                                                                                   edit_distance))\n",
    "            if checkpoint_dir:\n",
    "                if batch_idx % save_every == 0:\n",
    "                    save_checkpoint(encoder, decoder, checkpoint_dir)\n",
    "        tock = time.clock()\n",
    "        print(\"Time: {} Avg loss: {} Avg acc: {} Edit Dist.: {}\".format(\n",
    "            tock-tick, np.mean(losses), np.mean(accs), np.mean(eds)))\n",
    "    \n",
    "    if checkpoint_dir:\n",
    "        save_checkpoint(encoder, decoder, checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring and Initializing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configure models\n",
    "attn_model = 'dot'\n",
    "hidden_size = 100\n",
    "embed_size = 300\n",
    "n_layers = 1\n",
    "dropout = 0.1\n",
    "batch_size = 20\n",
    "checkpoint_dir = \"checkpoints\"\n",
    "\n",
    "# Configure training/optimization\n",
    "clip = 50.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jedi/anaconda3/envs/nlp/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "encoder = EncoderRNN(len(dataset.in_vocab[0]), embed_size, hidden_size, n_layers, dropout=dropout).to(device)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, hidden_size, len(dataset.out_vocab[0]), n_layers, dropout=dropout).to(device)\n",
    "\n",
    "# Initialize optimizers and criterion\n",
    "encoder_optimizer = optim.Adadelta(encoder.parameters())\n",
    "decoder_optimizer = optim.Adadelta(decoder.parameters())\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train(dataset, \n",
    "      batch_size, \n",
    "      n_epochs, \n",
    "      encoder, \n",
    "      decoder, \n",
    "      encoder_optimizer, \n",
    "      decoder_optimizer, \n",
    "      criterion, \n",
    "      checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Return attention weights and visualize them.\n",
    "2. Train model on full data (remove the max_length constraint).\n",
    "2. Train model with the Attention+Decoder that we learned in the previous lab\n",
    "3. Validate the model on [test data] (https://github.com/ryancotterell/sigmorphon2016/blob/master/data/german-task2-test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take Home Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How will you go about using MRI to improve LM and NMT? (think about using this in your project)\n",
    "2. Where else can apply MRI?\n",
    "3. What kind of improvements can be made to the current model? (hint: one way is to only learn what changes need to be made to the lemma given a form type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
